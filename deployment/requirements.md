# Requirements pour le D√©ploiement de Devana.ai

**Version:** 1.0
**Date:** Septembre 2025
**Audience:** Architectes d'entreprise, DevOps, D√©cideurs IT

---

## üìë Table des mati√®res

1. [Vue d'ensemble](#-vue-densemble)
2. [Architecture de la plateforme](#-architecture-de-la-plateforme)
3. [Requirements Mat√©riels](#-requirements-mat√©riels)
   - [Configuration minimale](#configuration-minimale-environnement-de-test--50-utilisateurs)
   - [Configuration production](#configuration-recommand√©e-production--100-500-utilisateurs)
   - [Configuration entreprise](#configuration-entreprise-1000-10-000-utilisateurs)
4. [Requirements LLM & Embeddings](#-requirements-llm--embeddings)
   - [Sc√©nario 1 : Cloud Providers](#sc√©nario-1--cloud-providers-openai-azure-openai-anthropic)
   - [Sc√©nario 2 : Auto-h√©berg√©](#sc√©nario-2--llm-auto-h√©berg√©s-recommand√©-pour-entreprises)
   - [Sc√©nario 3 : Hybride](#sc√©nario-3--hybride-recommand√©-pour-flexibilit√©)
5. [Requirements R√©seau](#-requirements-r√©seau)
6. [Requirements Stockage](#-requirements-stockage)
7. [Requirements S√©curit√©](#-requirements-s√©curit√©)
8. [Requirements Kubernetes](#-requirements-kubernetes)
9. [Monitoring & Observabilit√©](#-monitoring--observabilit√©)
10. [Ressources compl√©mentaires](#-ressources-compl√©mentaires)

---

## üìã Vue d'ensemble

Ce document sp√©cifie les exigences techniques pour le d√©ploiement de la plateforme Devana.ai en environnement d'entreprise. Il est con√ßu pour les organisations √† grande √©chelle n√©cessitant haute disponibilit√©, s√©curit√© renforc√©e et conformit√© r√©glementaire.

### Port√©e

- D√©ploiement on-premise ou cloud priv√©
- Architecture multi-environnements (dev, staging, production)
- Support de 100 √† 10 000+ utilisateurs concurrents
- Int√©gration avec infrastructure existante (SSO, r√©seau, stockage)

---

## üèóÔ∏è Architecture de la plateforme

### Composants principaux

La plateforme Devana.ai s'articule autour de 8 composants critiques :

| Composant | Technologie | R√¥le | Criticit√© |
|-----------|-------------|------|-----------|
| **Devana API** | Node.js 22.x | Backend principal, orchestration | ‚≠ê‚≠ê‚≠ê Critique |
| **Devana Frontend** | Next.js 15.x | Interface utilisateur web | ‚≠ê‚≠ê‚≠ê Critique |
| **Odin** | Python 3.12 | Traitement de documents, OCR, vectorisation | ‚≠ê‚≠ê‚≠ê Critique |
| **PostgreSQL** | 17.x | Base de donn√©es relationnelle | ‚≠ê‚≠ê‚≠ê Critique |
| **ChromaDB** | 1.0.6+ | Base de donn√©es vectorielle (RAG) | ‚≠ê‚≠ê‚≠ê Critique |
| **Meilisearch** | 1.13.3+ | Moteur de recherche plein texte | ‚≠ê‚≠ê Important |
| **Redis** | 7.4+ | Cache, sessions, files d'attente | ‚≠ê‚≠ê‚≠ê Critique |
| **S3/MinIO** | Compatible S3 | Stockage objets (fichiers utilisateurs) | ‚≠ê‚≠ê‚≠ê Critique |

### D√©pendances externes

- **LLM Provider** (OpenAI, Azure OpenAI, ou auto-h√©berg√©)
- **Embedding Model** (OpenAI, auto-h√©berg√© via vLLM/TGI)
- **Services optionnels** : SharePoint, Azure AD, services web externes

---

## üíª Requirements Mat√©riels

### Configuration minimale (Environnement de test / < 50 utilisateurs)

| Composant | CPU | RAM | Stockage | GPU | Notes |
|-----------|-----|-----|----------|-----|-------|
| **Devana API** | 2 cores | 4 GB | 20 GB SSD | - | Node.js + PM2 |
| **Frontend** | 1 core | 2 GB | 10 GB SSD | - | Next.js SSR |
| **Odin** | 2 cores | 4 GB | 30 GB SSD | - | Sans GPU : OCR basique |
| **PostgreSQL** | 2 cores | 8 GB | 100 GB SSD | - | + WAL logs |
| **ChromaDB** | 1 core | 4 GB | 50 GB SSD | - | Donn√©es vectorielles |
| **Meilisearch** | 1 core | 2 GB | 20 GB SSD | - | Index de recherche |
| **Redis** | 1 core | 2 GB | 10 GB SSD | - | Cache en m√©moire |
| **S3/MinIO** | 1 core | 2 GB | 500 GB+ | - | Selon volum√©trie |
| **TOTAL** | **11 cores** | **28 GB** | **740 GB** | - | Configuration de base |

### Configuration recommand√©e (Production / 100-500 utilisateurs)

| Composant | CPU | RAM | Stockage | GPU | R√©plicas HA |
|-----------|-----|-----|----------|-----|-------------|
| **Devana API** | 3 cores | 4 GB | 20 GB SSD | - | 2-3 pods |
| **Frontend** | 2 cores | 4 GB | 10 GB SSD | - | 2-3 pods |
| **Odin** | 3 cores | 6 GB | 50 GB SSD | Optionnel* | 2 pods |
| **PostgreSQL** | 4 cores | 16 GB | 500 GB SSD | - | 1 master + 2 replicas |
| **ChromaDB** | 2 cores | 8 GB | 200 GB SSD | - | 2-3 replicas |
| **Meilisearch** | 2 cores | 4 GB | 50 GB SSD | - | 2 replicas |
| **Redis** | 2 cores | 8 GB | 20 GB SSD | - | 1 master + 2 replicas |
| **S3/MinIO** | 2 cores | 8 GB | 2 TB+ | - | Cluster 4 nodes |
| **Load Balancer** | 2 cores | 4 GB | 10 GB | - | Nginx/HAProxy |
| **TOTAL (par n≈ìud)** | **8-12 cores** | **24-32 GB** | **1-3 TB** | - | 3 n≈ìuds min |

\* GPU pour Odin : recommand√© pour l'OCR haute performance (NVIDIA T4 ou sup√©rieur)

### Configuration entreprise (1000-10 000+ utilisateurs)

| Composant | CPU | RAM | Stockage | GPU | R√©plicas HA |
|-----------|-----|-----|----------|-----|-------------|
| **Devana API** | 4 cores/pod | 6 GB/pod | 30 GB SSD | - | 5-10 pods (HPA) |
| **Frontend** | 2 cores/pod | 4 GB/pod | 15 GB SSD | - | 5-10 pods (HPA) |
| **Odin** | 4 cores/pod | 8 GB/pod | 100 GB SSD | 1 GPU/pod | 3-5 pods |
| **PostgreSQL** | 8-16 cores | 64-128 GB | 2-5 TB NVMe | - | Cluster 3-5 nodes |
| **ChromaDB** | 4 cores/pod | 16 GB/pod | 1 TB SSD | - | 3-5 replicas |
| **Meilisearch** | 4 cores/pod | 8 GB/pod | 200 GB SSD | - | 3 replicas |
| **Redis** | 4 cores | 16 GB | 50 GB SSD | - | Cluster 6 nodes |
| **S3/MinIO** | 4 cores/node | 16 GB/node | 10+ TB | - | Cluster 8+ nodes |
| **Load Balancer** | 4 cores | 8 GB | 20 GB | - | HA pair |
| **Monitoring** | 4 cores | 16 GB | 500 GB | - | Prometheus+Grafana |

**Cluster Kubernetes recommand√© :**
- **N≈ìuds de calcul** : 10-20 n≈ìuds (32 cores, 128 GB RAM chacun)
- **N≈ìuds GPU** (LLM 70B+) : 4-8 n≈ìuds GPU (NVIDIA H100/H200)
- **N≈ìuds GPU** (Embeddings) : 2-3 n≈ìuds GPU (NVIDIA L4 ou L40S)
- **N≈ìuds de donn√©es** (PostgreSQL, ChromaDB) : 3-5 n≈ìuds (NVMe, 128-256 GB RAM)
- **R√©seau** : 100 Gbps minimum entre n≈ìuds GPU, 10 Gbps pour le reste

---

## ü§ñ Requirements LLM & Embeddings

### Sc√©nario 1 : Cloud Providers (OpenAI, Azure OpenAI, Anthropic)

**Avantages :**
- Pas d'infrastructure GPU n√©cessaire
- Scalabilit√© automatique
- Latence optimis√©e (CDN global)
- Co√ªts pr√©visibles (pay-per-token)

**Requirements :**
- **Bande passante** : 100 Mbps minimum (synchrone), 1 Gbps recommand√©
- **Latence** : < 100ms vers endpoints API (id√©alement < 50ms)
- **Disponibilit√©** : SLA 99.9% minimum (Azure/OpenAI)
- **Co√ªts estim√©s** (production, 1000 utilisateurs actifs) :
  - LLM : $5,000-$15,000/mois selon mod√®le et volume
  - Embeddings : $500-$2,000/mois

**Configuration r√©seau :**
```bash
# Whitelist endpoints
api.openai.com           # OpenAI
*.openai.azure.com       # Azure OpenAI
api.anthropic.com        # Claude
```

**Limitations :**
- D√©pendance externe critique
- Donn√©es transitent hors infrastructure (conformit√© RGPD/HIPAA)
- Contr√¥le limit√© sur latence et disponibilit√©

---

### Sc√©nario 2 : LLM Auto-h√©berg√©s (Recommand√© pour entreprises)

**Avantages :**
- Contr√¥le total des donn√©es (on-premise)
- Latence pr√©visible (<10ms en r√©seau local)
- Conformit√© r√©glementaire garantie
- Co√ªts fixes apr√®s investissement initial

#### Requirements mat√©riels par mod√®le

**Mod√®les de production (recommand√©s)**

| Mod√®le | Taille | GPU Recommand√© | VRAM | RAM syst√®me | Latence | Throughput |
|--------|--------|----------------|------|-------------|---------|------------|
| **Llama 3.1 70B** | 70B params | 2x H100 (80GB) | 160 GB | 512 GB | ~80ms | 100 tokens/s |
| **Llama 3.3 70B** | 70B params | 2x H100 (80GB) | 160 GB | 512 GB | ~80ms | 100 tokens/s |
| **Mixtral 8x22B** | 141B params | 4x H100 (80GB) | 320 GB | 768 GB | ~150ms | 60 tokens/s |
| **Qwen 2.5 72B** | 72B params | 2x H100 (80GB) | 160 GB | 512 GB | ~85ms | 95 tokens/s |
| **DeepSeek V3** | 671B params | 8x H200 (141GB) | 1128 GB | 2048 GB | ~300ms | 40 tokens/s |

**GPU nouvelle g√©n√©ration (recommand√©s)**

| GPU | VRAM | Architecture | Use Case | Disponibilit√© |
|-----|------|--------------|----------|---------------|
| **NVIDIA H100 SXM** | 80 GB | Hopper | Production 70B-141B | ‚≠ê Recommand√© |
| **NVIDIA H200** | 141 GB | Hopper+ | Production 141B-671B | ‚≠ê‚≠ê Optimal |
| **NVIDIA A100** | 80 GB | Ampere | Alternative 70B | Acceptable |

**Configuration recommand√©e (production) :**
- **LLM principal** : 2x serveurs GPU (Llama 3.3 70B ou Qwen 2.5 72B)
  - GPU : 2x NVIDIA H100 80GB par serveur (ou 2x H200 141GB pour mod√®les >100B)
  - CPU : 64 cores (AMD EPYC 9004 series ou Intel Xeon Sapphire Rapids)
  - RAM : 512 GB DDR5
  - Stockage : 4 TB NVMe Gen4 (mod√®les + cache)
  - R√©seau : 400 Gbps InfiniBand ou 100 Gbps Ethernet

- **Embedding Model** : 2x serveurs GPU (e5-mistral-7b-instruct ou gte-Qwen2-7B)
  - GPU : 1x NVIDIA L4 24GB par serveur
  - CPU : 16 cores
  - RAM : 128 GB
  - Stockage : 1 TB NVMe
  - R√©seau : 25 Gbps

**Architectures support√©es :**
- **vLLM** : Plateforme de serving haute performance (recommand√©)
- **TGI** (Text Generation Inference) : Solution Hugging Face
- **Ollama** : D√©ploiement simplifi√© (dev/test uniquement)
- **TensorRT-LLM** : Performance maximale (NVIDIA)

**Exemple de d√©ploiement vLLM (Kubernetes) :**
```yaml
# Voir cluster-embeddings/embedding.yml pour r√©f√©rence compl√®te
resources:
  limits:
    nvidia.com/gpu: 1     # Par r√©plica
    cpu: "4"
    memory: "24Gi"
replicas: 2                # Haute disponibilit√©
```

**Scalabilit√© (mod√®les 70B+) :**
- **100-500 utilisateurs** : 2x H100 80GB (Llama 3.3 70B)
- **500-2000 utilisateurs** : 4x H100 80GB (2 serveurs en load balancing)
- **2000-5000 utilisateurs** : 8x H100 80GB (4 serveurs) ou 4x H200 141GB
- **5000-10000 utilisateurs** : Cluster GPU d√©di√© (12-16x H100 ou 8-12x H200)

**Note :** Les petits mod√®les (<70B) ne sont pas recommand√©s pour un usage production enterprise-grade n√©cessitant des capacit√©s de raisonnement avanc√©es.

---

### Sc√©nario 3 : Hybride (Recommand√© pour flexibilit√©)

**Configuration :**
- LLM principal : Auto-h√©berg√© (donn√©es sensibles)
- LLM secondaire : Cloud (fallback, pic de charge)
- Embeddings : Auto-h√©berg√© (volum√©trie √©lev√©e)

**B√©n√©fices :**
- R√©silience maximale
- Optimisation co√ªts
- Conformit√© assur√©e sur donn√©es critiques

---

## üåê Requirements R√©seau

### Bande passante

| Usage | Minimum | Recommand√© | Notes |
|-------|---------|------------|-------|
| **Interne (pod-to-pod)** | 1 Gbps | 10 Gbps | Latence critique |
| **Externe (utilisateurs)** | 100 Mbps | 1 Gbps | Selon charge |
| **LLM Cloud** | 50 Mbps | 500 Mbps | Streaming tokens |
| **Backup & Sync** | - | 1 Gbps+ | Hors heures de pointe |

### Latence maximale acceptable

| Connexion | Max acceptable | Optimal | Impact si d√©pass√© |
|-----------|----------------|---------|-------------------|
| Frontend ‚Üî API | 200ms | < 50ms | UX d√©grad√©e |
| API ‚Üî PostgreSQL | 10ms | < 2ms | Performance critique |
| API ‚Üî ChromaDB | 50ms | < 10ms | Lenteur RAG |
| API ‚Üî LLM | 500ms | < 100ms | Timeout utilisateur |
| API ‚Üî Redis | 5ms | < 1ms | Cache inefficace |

### Ports requis

#### Externes (Internet)
| Port | Protocole | Service | Justification |
|------|-----------|---------|---------------|
| 443 | HTTPS | Frontend, API | Acc√®s utilisateurs |
| 80 | HTTP | Redirection HTTPS | Automatique |

#### Internes (Cluster)
| Port | Service | Notes |
|------|---------|-------|
| 4666 | Devana API | HTTP/GraphQL |
| 5001 | WebSocket | Temps r√©el |
| 3000 | Frontend | Next.js SSR |
| 3003 | Odin | API interne |
| 5432 | PostgreSQL | Base de donn√©es |
| 8000 | ChromaDB | Vector DB |
| 7700 | Meilisearch | Recherche |
| 6379 | Redis | Cache |
| 9000 | MinIO | S3-compatible |

### R√®gles Firewall (exemples)

```bash
# Production - R√®gles strictes
# Frontend accessible uniquement via Load Balancer
LB -> Frontend:3000 (ALLOW)
* -> Frontend:3000 (DENY)

# API accessible uniquement depuis Frontend et LB
Frontend -> API:4666,5001 (ALLOW)
LB -> API:4666 (ALLOW)
* -> API:4666,5001 (DENY)

# Services internes isol√©s
API -> PostgreSQL:5432 (ALLOW)
API -> ChromaDB:8000 (ALLOW)
API -> Redis:6379 (ALLOW)
API -> Odin:3003 (ALLOW)
* -> Services-internes:* (DENY)

# LLM/Embeddings (si auto-h√©berg√©)
API -> LLM-Cluster:8000 (ALLOW)
Odin -> Embeddings:8000 (ALLOW)
* -> LLM-Cluster:8000 (DENY)
```

---

## üíæ Requirements Stockage

### Dimensionnement par volume

| Utilisateurs | Documents/user | Stockage total | Croissance annuelle |
|--------------|----------------|----------------|---------------------|
| 100 | 500 | 500 GB | +200 GB/an |
| 500 | 500 | 2 TB | +1 TB/an |
| 1,000 | 500 | 5 TB | +2 TB/an |
| 5,000 | 500 | 25 TB | +10 TB/an |
| 10,000 | 500 | 50 TB | +20 TB/an |

**Calcul d√©taill√© (1000 utilisateurs) :**
- **Fichiers utilisateurs** (S3/MinIO) : 5 TB (500 docs √ó 10 MB avg √ó 1000 users)
- **Base de donn√©es PostgreSQL** : 500 GB (m√©tadonn√©es, conversations, logs)
- **ChromaDB** (vecteurs) : 200 GB (1000 dims √ó 4 bytes √ó 50M chunks)
- **Meilisearch** (index) : 100 GB (index invers√© + cache)
- **Redis** (cache) : 20 GB (sessions + cache applicatif)
- **Backups** : 6 TB (retention 30 jours, snapshots quotidiens)
- **Logs** : 50 GB/mois (application + syst√®me)

**Total :** ~12 TB avec marge de 30%

### Performances requises

| Composant | IOPS | Throughput | Type de stockage |
|-----------|------|------------|------------------|
| **PostgreSQL** | 10,000+ | 500 MB/s | NVMe SSD (local) |
| **ChromaDB** | 5,000+ | 300 MB/s | SSD (local ou SAN) |
| **S3/MinIO** | 1,000+ | 1 GB/s | HDD RAID ou SSD |
| **Logs** | 500+ | 50 MB/s | SSD |

### Strat√©gie de backup

**RTO (Recovery Time Objective) : < 4h**
**RPO (Recovery Point Objective) : < 15min**

- **PostgreSQL** : WAL archiving + snapshots quotidiens
- **ChromaDB** : Snapshots quotidiens (donn√©es reconstructibles)
- **S3/MinIO** : R√©plication g√©ographique + snapshots hebdomadaires
- **Redis** : RDB snapshots + AOF (append-only file)

---

## üîí Requirements S√©curit√©

### Conformit√© r√©glementaire

| Standard | Requis si | Mesures Devana.ai |
|----------|-----------|-------------------|
| **RGPD** | Donn√©es UE | ‚úÖ Chiffrement at-rest/in-transit, droit √† l'oubli |
| **ISO 27001** | Certification s√©curit√© | ‚ö†Ô∏è Conformit√© aux bonnes pratiques (non certifi√©) |
| **SOC 2 Type II** | SaaS compliance | ‚ö†Ô∏è Conformit√© aux bonnes pratiques (non certifi√©) |
| **HIPAA** | Donn√©es sant√© US | ‚ö†Ô∏è Configuration sp√©cifique requise |
| **HDS** | H√©bergement sant√© FR | ‚ö†Ô∏è Datacenter certifi√© requis |

### Chiffrement

**At-Rest :**
- PostgreSQL : Chiffrement TDE (Transparent Data Encryption)
- S3/MinIO : AES-256 (SSE-S3 ou SSE-KMS)
- Disques : LUKS ou √©quivalent

**In-Transit :**
- TLS 1.3 minimum (1.2 acceptable avec ciphers forts)
- Certificats sign√©s (Let's Encrypt ou CA interne)
- Mutual TLS pour services internes (optionnel mais recommand√©)

### Authentification & Autorisation

**SSO requis (production) :**
- OIDC / OAuth 2.0
- SAML 2.0
- LDAP / Active Directory

**RBAC (Role-Based Access Control) :**
- Admin syst√®me
- Admin organisation
- Gestionnaire d'agents
- Utilisateur standard
- Utilisateur lecture seule

**Audit Logs :**
- Toutes actions admin
- Acc√®s aux donn√©es sensibles
- Modifications de configuration
- Retention : 1 an minimum

### Isolation r√©seau

**Zones de s√©curit√© :**
```
[Internet] ‚Üí [DMZ: LB, WAF] ‚Üí [App: Frontend, API] ‚Üí [Data: DB, Storage]
                                                    ‚Üí [AI: LLM, Embeddings]
```

**Segmentation r√©seau (VLANs/Subnets) :**
- **DMZ** : Load Balancers, Reverse Proxy (10.0.1.0/24)
- **Application** : Frontend, API (10.0.10.0/24)
- **Services** : Odin, Redis, Meilisearch (10.0.20.0/24)
- **Donn√©es** : PostgreSQL, ChromaDB (10.0.30.0/24)
- **AI** : LLM, Embeddings (10.0.40.0/24)
- **Management** : Monitoring, Backup (10.0.99.0/24)

---

## ‚ò∏Ô∏è Requirements Kubernetes

### Version

- **Minimum** : Kubernetes 1.31+
- **Recommand√©** : Kubernetes 1.32+ ou OpenShift 4.19+
- **Distributions support√©es** :
  - Vanilla Kubernetes
  - Red Hat OpenShift
  - Rancher RKE2
  - VMware Tanzu
  - Amazon EKS / Azure AKS / Google GKE (cloud priv√©)

### Addons conseill√©s

| Addon | Usage | Recommandation |
|-------|-------|----------------|
| **Ingress Controller** | Routing HTTP/S | Nginx Ingress ou Traefik |
| **Cert Manager** | Certificats TLS | Let's Encrypt ou CA interne |
| **MetalLB** | Load Balancer on-prem | Si pas de LB mat√©riel |
| **CSI Driver** | Stockage persistant | Rook-Ceph, Longhorn, ou SAN |
| **GPU Operator** | Support GPU NVIDIA | Si LLM auto-h√©berg√©s |
| **Prometheus** | Monitoring | + Grafana pour visualisation |
| **Loki** | Logs agr√©g√©s | Ou ELK stack |

### Namespaces recommand√©s

```yaml
- devana-prod          # Application production
- devana-staging       # Pre-production
- devana-services      # Services partag√©s (DB, Redis)
- devana-ai            # LLM & Embeddings
- monitoring           # Prometheus, Grafana, Loki
- cert-manager         # Gestion certificats
```

### Storage Classes

```yaml
# Haute performance (PostgreSQL, ChromaDB)
storageClassName: fast-ssd
provisioner: kubernetes.io/no-provisioner  # Local NVMe
volumeBindingMode: WaitForFirstConsumer

# Standard (logs, backups)
storageClassName: standard
provisioner: kubernetes.io/aws-ebs  # Ou √©quivalent

# Objets (S3/MinIO via CSI)
storageClassName: s3-csi
provisioner: ru.yandex.s3.csi
```

---

## üìä Monitoring & Observabilit√©

### M√©triques critiques √† surveiller

| Cat√©gorie | M√©trique | Seuil d'alerte | Action |
|-----------|----------|----------------|--------|
| **API** | Latency p95 | > 500ms | Scale horizontalement |
| **API** | Error rate | > 1% | Investigate logs |
| **PostgreSQL** | Connections | > 80% max | Scale ou optimize queries |
| **PostgreSQL** | Slow queries | > 1s | Index manquants |
| **ChromaDB** | Query latency | > 200ms | Scale ou optimize embeddings |
| **Redis** | Memory usage | > 80% | Increase RAM ou eviction |
| **LLM** | Tokens/sec | < 50 | Scale GPU ou model |
| **Odin** | Queue size | > 100 | Scale pods |

### Stack recommand√©

- **Prometheus** : M√©triques syst√®me + applicatives
- **Grafana** : Dashboards + alerting
- **Loki** : Logs agr√©g√©s (alternative √† ELK)
- **Jaeger / Tempo** : Tracing distribu√© (optionnel)
- **OpenTelemetry** : Instrumentation standardis√©e

### Alerting critique

```yaml
# Exemples de r√®gles Prometheus
- alert: APIHighLatency
  expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 0.5
  for: 5m
  severity: warning

- alert: PostgreSQLDown
  expr: up{job="postgresql"} == 0
  for: 1m
  severity: critical

- alert: LLMGPUMemoryHigh
  expr: nvidia_gpu_memory_used_bytes / nvidia_gpu_memory_total_bytes > 0.9
  for: 10m
  severity: warning
```

---

## üìö Ressources compl√©mentaires

### Documentation technique

- [Guide de d√©ploiement Kubernetes](./infrastructure/kubernetes/kube/README.md)
- [Configuration des variables d'environnement](./configuration/environment-variables.md)
- [Ajout de mod√®les personnalis√©s](./configuration/add-custom-model.md)
- [Configuration SSO](./authentication/README.md)
- [Monitoring et health checks](./monitoring/health-checks.md)

### Ressources externes

- **vLLM Documentation** : https://docs.vllm.ai
- **Kubernetes Best Practices** : https://kubernetes.io/docs/concepts/
- **PostgreSQL Performance Tuning** : https://wiki.postgresql.org/wiki/Performance_Optimization
- **NVIDIA GPU Operator** : https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/

---

## üîÑ Historique des r√©visions

| Version | Date | Auteur | Modifications |
|---------|------|--------|---------------|
| 1.0 | Sept 2025 | Devana.ai | Cr√©ation initiale |

---

**Note l√©gale :** Ce document est confidentiel et destin√© uniquement aux clients et partenaires de Scriptor Group. Toute reproduction ou diffusion est interdite sans autorisation √©crite.

**¬© 2025 Scriptor Group - Tous droits r√©serv√©s**