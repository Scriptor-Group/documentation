# D√©ploiement Devana.ai

Documentation compl√®te pour le d√©ploiement de Devana.ai en environnement on-premise ou cloud priv√©.

> **Confidentialit√©** : Ce document contient des informations sensibles. Ne pas diffuser sans autorisation.
>
> **Support** : Pour toute question, contactez support-it@devana.ai

## üìö Documentation par section

### üöÄ [Requirements & Dimensionnement](./requirements.md)
**‚≠ê Commencez ici** - Documentation compl√®te des requirements mat√©riels, logiciels, r√©seau et s√©curit√© pour d√©ployer Devana.ai. Inclut le dimensionnement pour LLM/Embeddings auto-h√©berg√©s.

- Requirements mat√©riels par taille d'organisation
- Dimensionnement LLM & Embeddings (cloud vs auto-h√©berg√©)
- Requirements r√©seau et latence
- S√©curit√© et conformit√© (RGPD, ISO 27001, SOC 2)
- Checklist de d√©ploiement compl√®te

### ‚öôÔ∏è Configuration
- [Variables d'environnement](./configuration/environment-variables.md) - Configuration compl√®te de tous les services
- [Ajout de mod√®les personnalis√©s](./configuration/add-custom-model.md) - LLM & Embeddings auto-h√©berg√©s
- [Template de documentation agent](./configuration/agent-template.md) - Cr√©ation d'agents personnalis√©s

### üèóÔ∏è Infrastructure
- [Kubernetes](./infrastructure/kubernetes/kube/README.md) - D√©ploiement sur cluster K8s/OpenShift
- [Base de donn√©es PostgreSQL](./infrastructure/database/db/postgresql.md) - Configuration et tuning
- [Azure Cloud](./infrastructure/azure/azure/README.md) - D√©ploiement sp√©cifique Azure (WIP)

### üîê Authentification
- [Vue d'ensemble SSO](./authentication/README.md) - Providers support√©s
- Configuration par provider : [Azure AD](./authentication/sso/azure.md), [Google](./authentication/sso/google.md), [LDAP](./authentication/sso/ldap.md), [OIDC](./authentication/sso/oidc.md), etc.

### üìä Monitoring & Services
- [Health Checks](./monitoring/health-checks.md) - Surveillance de la plateforme
- [Gestion des licences](./monitoring/license.md) - Monitoring d'utilisation
- [Architecture des services](./services/services/) - Devana API, Odin

### üîß Troubleshooting
- [Probl√®mes courants](./troubleshooting/common-issues.md) - Guide de r√©solution
- [Migrations](./troubleshooting/migration-sharepoint.md) - Guides de migration sp√©cifiques

---

## Infrastructure

**L'infrastructure Devana est compos√©e de plusieurs √©l√©ments cl√©s :**
* Un cluster Kubernetes pour orchestrer les diff√©rents services et assurer la scalabilit√© et la haute disponibilit√©
* Une base de donn√©es PostgreSQL pour stocker les donn√©es structur√©es de l'application
* Un serveur de fichiers S3 (comme Amazon S3 ou MinIO) pour stocker les fichiers et les donn√©es non structur√©es
* Un serveur Redis pour la mise en cache et la gestion des sessions

Voici un diagramme expliquant l'architecture de l'infrastructure Devana pour le on-premise :

```mermaid
graph TD
    %% D√©finition des sous-graphes External
    subgraph External["Services Externes"]
        subgraph Databases["Bases de donn√©es"]
            PostgreSQL[PostgreSQL]
            Redis[Redis]
            S3Bucket["S3 Bucket"]
        end
        subgraph AI["Services IA"]
            LLMServer["LLM Server"]
            VisionServer["Vision Server"]
            EmbeddingServer["Embedding Server"]
        end
    end

    %% D√©finition du cluster Kubernetes/OpenShift
    subgraph Kubernetes["Cluster Kubernetes/OpenShift"]

        subgraph Core["Services Principaux"]
            subgraph FrontendStack["Frontend"]
                PodFrontend["Pod Frontend"]
                SvcFrontend["Svc Frontend"]
            end

            subgraph APIStack["API"]
                PodAPI["Pod API"]
                SvcAPI["Svc API"]
            end
        end

        subgraph Search["Services de Recherche"]
            subgraph VectorDB["Base Vectorielle"]
                PodVectorDB["Pod VectorDB"]
                SvcVectorDB["Svc VectorDB"]
            end

            subgraph SearchEngine["Moteur de Recherche"]
                PodMeiliSearch["Pod MeiliSearch"]
                SvcMeiliSearch["Svc MeiliSearch"]
            end
        end

        subgraph Parser["Service Parser"]
            subgraph OdinPod["Odin - multi-container pod"]
                PodOdin["Pod Odin"]
                PodGotenberg["Pod Gotenberg"]
                PodNats["Pod Nats"]
            end
            SvcParser["Svc Parser"]
        end

        Ingress[Ingress]
        SSLTermination["SSL Termination"]
    end

    %% D√©finition des utilisateurs
    subgraph Users["Utilisateurs"]
        AppUsers[Users]
        TeamsAgents["Teams Agents"]
    end

    %% Connexions Frontend
    SvcFrontend --> PodFrontend

    %% Connexions API
    SvcAPI --> PodAPI

    %% Connexions VectorDB
    SvcVectorDB --> PodVectorDB

    %% Connexions MeiliSearch
    SvcMeiliSearch --> PodMeiliSearch

    %% Connexions vers External Services depuis l'API
    PodAPI -.-> Databases
    PodAPI -.-> AI

    %% Connexions inter-services
    PodAPI --> SvcVectorDB
    PodAPI --> SvcMeiliSearch
    PodAPI --> SvcParser
    PodFrontend --> SvcAPI

    %% Connexions Ingress et utilisateurs
    Ingress --> SvcAPI
    Ingress --> SvcFrontend
    SSLTermination --> Ingress
    AppUsers --> SSLTermination
    TeamsAgents --> SSLTermination

    %% Connexions au sein du pod Odin
    PodOdin --> PodGotenberg
    PodOdin --> PodNats
    PodOdin -.-> Databases
    SvcParser --> PodOdin

    direction TB
```

Le cluster Kubernetes est au c≈ìur de l'infrastructure et g√®re les diff√©rents services de l'application Devana. Il communique avec la base de donn√©es PostgreSQL pour la persistance des donn√©es, avec le serveur de fichiers S3 pour le stockage des fichiers, et avec le serveur Redis pour la mise en cache et la gestion des sessions. Concernant Redis, vous pouvez √©galement utiliser un cluster Redis si vous souhaitez l'heberger directement dans kubernetes.

## R√©seau

[![Sch√©ma Network](./assets/on-prem-network2.svg)](https://excalidraw.com/#json=IWUTffmcXZpIfPwLVADe9,2kCA4Wk5fC73tNGCHc_Fzg)

Ce sch√©ma r√©seau pr√©sente un cas particulier de mise en place de Devana. Il n'est pas valable pour chaque cas.

## Compatibilit√©

Le on-premise de Devana est compatible avec les principales plateformes de cloud computing :
- **Microsoft Azure**: Devana peut √™tre d√©ploy√© sur Azure Kubernetes Service (AKS) et utiliser Azure Database pour PostgreSQL, Azure Blob Storage et Azure Cache pour Redis.
- **Amazon Web Services (AWS)**: Devana est compatible avec Amazon Elastic Kubernetes Service (EKS), Amazon RDS pour PostgreSQL, Amazon S3 et Amazon ElastiCache pour Redis.
- **Google Cloud Platform (GCP)**: Devana peut √™tre install√© sur Google Kubernetes Engine (GKE), avec Cloud SQL pour PostgreSQL, Google Cloud Storage et Memorystore pour Redis.

Pour chaque plateforme, il est n√©cessaire de respecter les pr√©requis suivants :
- Un cluster Kubernetes/OpenShift (version 1.19 ou sup√©rieure) avec au moins 3 n≈ìuds
- Une base de donn√©es PostgreSQL (version 12 ou sup√©rieure)
- Un serveur de fichiers S3 compatible
- Un serveur Redis (version 6 ou sup√©rieure)

Avant de proc√©der √† l'installation de Devana, assurez-vous que votre infrastructure remplit ces conditions et que vous disposez des acc√®s et autorisations n√©cessaires pour cr√©er et g√©rer les ressources sur votre plateforme de cloud.

## Recommandations de performance par pod

Pour garantir des performances optimales de l'application Devana, il est important de dimensionner correctement les ressources allou√©es √† chaque pod. Voici quelques recommandations pour les principaux composants :

### Odin

- CPU : **3 vCPU**
- RAM : **6 Go**
- Disque : **20 Go**

Odin est un multi-container pod, il est donc important de r√©partir les ressources ci-dessus aux diff√©rents container du pod.

> Nous recommandons d'utiliser un r√©plica set de minimum 4 pods pour garantir la haute disponibilit√© du service en cas de d√©p√¥t de plusieurs documents en simultan√©s.
>
> Lors d'un premier run, nous vous recommandons de lancer un ensemble de X pods afin d'absorber les premiers documents de l'entreprise. Vous pouvez par la suite r√©duire le nombre de prods √† 4 pods minimum. 

### Gotenberg

- CPU : **2 vCPU**
- RAM : **3 Go**
- Disque : **10 Go**


### API

- CPU : **3 vCPU**
- RAM : **4 Go**
- Disque : **10 Go**

> Nous recommandons d'utiliser un r√©plica set de minimum 2 pods pour garantir la haute disponibilit√©.

### Frontend

- CPU : 1 vCPU
- RAM : 1 Go
- Disque : 5 Go

> Nous recommandons d'utiliser un r√©plica set de minimum 2 pods pour garantir la haute disponibilit√©.

### BDD Vectorielle

- CPU : 3 vCPU (selon la taille de votre base de donn√©es)
- RAM : 2 Go (selon la quantit√© de donn√©es)
- Disque : 100 Go (selon la taille de votre base de donn√©es)

> Vous devez lancer un seul pod pour le service de la base de donn√©es vectorielle.

### Redis

- CPU : 1 vCPU
- RAM : 2 Go
- Disque : 10 Go

> Vous devez lancer un seul pod pour le service de Redis.

*Si vous utilisez un cluster Redis g√©r√© par votre fournisseur de cloud, r√©f√©rez-vous √† leurs recommandations sp√©cifiques.*

### Meilisearch
[Pour plus d'informations](https://www.meilisearch.com/docs/learn/resources/faq#faq)
- CPU : 2 vCPU (peu impactant sur la vitesse, mais plus de c≈ìurs permettent de g√©rer plus de requ√™tes simultan√©ment)
- RAM : 4 Go (plus la RAM est √©lev√©e, plus les performances sont optimis√©es)
- Disque : 50 Go (minimum 10x la taille du dataset, SSD recommand√©)


Ces recommandations sont donn√©es √† titre indicatif et peuvent varier en fonction de votre charge de travail et du nombre d'utilisateurs. Il est conseill√© de surveiller r√©guli√®rement les performances de votre application et d'ajuster les ressources en cons√©quence.

## Test de performance
Nous avons utilis√© un script Python avec Selenium et du multithreading pour r√©aliser un test de charge bas√© sur un navigateur web. Ce script nous fournit le taux de r√©ussite, le temps moyen de connexion ainsi que le temps moyen pour recevoir une r√©ponse. Ce test a √©t√© effectu√© sur une base de connaissances comprenant des informations sur Devana de mani√®re g√©n√©rale, avec un agent connect√© √† cette base et √† GPT4O-Mini. Le parcours utilisateur simul√© consistait √† acc√©der √† Devana, se connecter, s√©lectionner un agent, puis envoyer et recevoir une question/r√©ponse.

- Taux de r√©ussite : le pourcentage de threads ayant r√©ussi √† accomplir les t√¢ches impos√©es, √† savoir :
  - 10 secondes d'attente maximum apr√®s avoir cliqu√© sur le bouton de connexion.
  - 5 secondes d'attente maximum entre chaque page.
  - 30 secondes d'attente maximum pour que l'agent retourne une r√©ponse apr√®s une question.
- Temps moyen pour se connecter : la moyenne du temps n√©cessaire pour que les threads passent de l'initialisation √† l'√©tat connect√©.
- Temps moyen pour recevoir une r√©ponse : la moyenne du temps pris par les threads pour compl√©ter le parcours utilisateur, c'est-√†-dire recevoir une r√©ponse de l'agent.

Pour obtenir un taux de r√©ussite de 100%, avec un d√©calage de 1s entre le d√©but de chaque thread, le nombre maximum de threads est de 25, soit 25 utilisateurs simultan√©s. Pour augmenter ce nombre, il suffit de multiplier les conteneurs.

```
--- R√©sum√© des m√©triques ---
Temps moyen pour le login : 12.06 secondes
Temps moyen pour recevoir une r√©ponse : 36.20 secondes
Pourcentage de succ√®s : 100.00%
```

## D√©tails des Donn√©es Collect√©es pour la V√©rification de Licence et la Maintenance

Dans le cadre de l'utilisation de Devana on-prem, notre serveur de licence collecte automatiquement certaines m√©triques de votre syst√®me toutes les 5 minutes. Ces donn√©es sont essentielles pour assurer la conformit√© avec le contrat de licence et faciliter la maintenance proactive. Les m√©triques recueillies incluent :

- **Utilisation du CPU** : Nous surveillons l'utilisation du processeur, en calculant les pourcentages d'utilisation pour les diff√©rents √©tats (utilisateur, syst√®me, idle, irq) afin d'√©valuer les performances du syst√®me.
- **Utilisation de la M√©moire** : Nous collectons des informations sur la m√©moire totale, la m√©moire libre et la m√©moire utilis√©e de la machine pour surveiller les ressources disponibles.
- **Statistiques Utilisateurs et Messages** : Nous comptons le nombre total d'utilisateurs, le nombre de messages envoy√©s, et le nombre de tokens utilis√©s, afin de comprendre l'usage de la plateforme.
- **Nombre d'Agents et de Bases de Connaissances** : Nous suivons le nombre d'agents et de bases de connaissances actifs pour optimiser l'efficacit√© de la solution.
- **Informations R√©seau** : Nous enregistrons les d√©tails des interfaces r√©seau (nom, adresse IP, adresse MAC) pour diagnostiquer et r√©soudre d'√©ventuels probl√®mes de connectivit√©.
- **Informations sur le Processus** : Nous collectons l'identifiant du processus courant pour le suivi des performances et le d√©pannage.

Ces donn√©es sont transmises de mani√®re s√©curis√©e √† notre serveur de m√©triques pour garantir que votre utilisation de Devana reste conforme aux termes de la licence et pour nous aider √† fournir un support technique efficace en cas de besoin. La collecte r√©guli√®re de ces informations permet √©galement de pr√©venir et de r√©soudre plus rapidement les √©ventuels probl√®mes techniques.

# Installation

Pour effectuer l'installation de Devana, vous devez suivre les √©tapes d√©crites dans le document suivant : 
- [Installation Kubernetes](./infrastructure/kubernetes/kube/README.md).
- [Tutoriels Azure](./infrastructure/azure/azure/README.md) *(en cours de r√©daction)*

# D√©ploiement de la base de donn√©es

Pour d√©ployer la base de donn√©es PostgreSQL de Devana, vous pouvez suivre les instructions pr√©sentes dans le document suivant :
- [D√©ploiement de la base de donn√©es](./infrastructure/database/db/postgresql.md).

# Ajout d'un model

Pour ajouter un mod√®le personnalis√© √† Devana, vous pouvez l'ajouter via l'interface d'administration de Devana ou en utilisant l'acc√®s base de donn√©es, vous pouvez suivre les instructions pr√©sentes dans le document suivant :
- [Ajout d'un mod√®le personnalis√©](./configuration/add-custom-model.md).

